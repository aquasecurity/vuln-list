{
  "id": "GHSA-grg2-63fw-f2qr",
  "modified": "2026-01-13T19:22:54.327220Z",
  "published": "2026-01-13T18:44:15Z",
  "aliases": [
    "CVE-2026-22773"
  ],
  "summary": "vLLM is vulnerable to DoS in Idefics3 vision models via image payload with ambiguous dimensions",
  "details": "### Summary\nUsers can crash the vLLM engine serving multimodal models that use the _Idefics3_ vision model implementation by sending a specially crafted 1x1 pixel image. This causes a tensor dimension mismatch that results in an unhandled runtime error, leading to complete server termination.\n\n### Details\nThe vulnerability is triggered when the image processor encounters a 1x1 pixel image with shape (1, 1, 3) in HWC (Height, Width, Channel) format. Due to the ambiguous dimensions, the processor incorrectly assumes the image is in CHW (Channel, Height, Width) format with shape (3, H, W). This misinterpretation causes an incorrect calculation of the number of image patches, resulting in a fatal tensor split operation failure.\n\n**Crash location**: `vllm/model_executor/models/idefics3.py` line 672:\n```python\ndef _process_image_input(self, image_input: ImageInputs) -\u003e torch.Tensor | list[torch.Tensor]:\n    # ...\n    num_patches = image_input[\"num_patches\"]\n    return [e.flatten(0, 1) for e in image_features.split(num_patches.tolist())]\n```\n\nThe `split()` call fails because the computed `num_patches` value (17) does not match the actual tensor dimension (9):\n```\nRuntimeError: split_with_sizes expects split_sizes to sum exactly to 9 \n(input tensor's size at dimension 0), but got split_sizes=[17]\n```\n\nThis unhandled exception terminates the EngineCore process, crashing the server.\n\n#### Affected Models\nAny model using the Idefics3 architecture. The vulnerability was tested with `HuggingFaceTB/SmolVLM-Instruct`.\n\n### Impact\nDenial of service by crashing the engine\n\n### Mitigation\nValidating the input:\n```python\ndef _validate_image_dimensions(self, image_shape):\n    h, w = image_shape[:2] if len(image_shape) == 3 else image_shape\n    if h \u003c MIN_IMAGE_SIZE or w \u003c MIN_IMAGE_SIZE:\n        raise ValueError(f\"Image dimensions too small: {h}x{w}\")\n```\n\nManaging the exception:\n```python\ntry:\n    return [e.flatten(0, 1) for e in image_features.split(num_patches.tolist())]\nexcept RuntimeError as e:\n    logger.error(f\"Image processing failed: {e}\")\n    raise InvalidImageError(\"Failed to process image features\") from e\n```\n\n### Fixes\n\n* https://github.com/vllm-project/vllm/pull/29881",
  "affected": [
    {
      "package": {
        "ecosystem": "PyPI",
        "name": "vllm",
        "purl": "pkg:pypi/vllm"
      },
      "ranges": [
        {
          "type": "ECOSYSTEM",
          "events": [
            {
              "introduced": "0.6.4"
            },
            {
              "fixed": "0.12.0"
            }
          ]
        }
      ],
      "versions": [
        "0.10.0",
        "0.10.1",
        "0.10.1.1",
        "0.10.2",
        "0.11.0",
        "0.11.1",
        "0.11.2",
        "0.6.4",
        "0.6.4.post1",
        "0.6.5",
        "0.6.6",
        "0.6.6.post1",
        "0.7.0",
        "0.7.1",
        "0.7.2",
        "0.7.3",
        "0.8.0",
        "0.8.1",
        "0.8.2",
        "0.8.3",
        "0.8.4",
        "0.8.5",
        "0.8.5.post1",
        "0.9.0",
        "0.9.0.1",
        "0.9.1",
        "0.9.2"
      ],
      "database_specific": {
        "source": "https://github.com/github/advisory-database/blob/main/advisories/github-reviewed/2026/01/GHSA-grg2-63fw-f2qr/GHSA-grg2-63fw-f2qr.json"
      }
    }
  ],
  "references": [
    {
      "type": "WEB",
      "url": "https://github.com/vllm-project/vllm/security/advisories/GHSA-grg2-63fw-f2qr"
    },
    {
      "type": "ADVISORY",
      "url": "https://nvd.nist.gov/vuln/detail/CVE-2026-22773"
    },
    {
      "type": "WEB",
      "url": "https://github.com/vllm-project/vllm/pull/29881"
    },
    {
      "type": "WEB",
      "url": "https://github.com/vllm-project/vllm/commit/0ec84221718d920c3f46da879cc354f94b8fb59e"
    },
    {
      "type": "PACKAGE",
      "url": "https://github.com/vllm-project/vllm"
    }
  ]
}