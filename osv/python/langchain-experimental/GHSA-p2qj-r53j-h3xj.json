{
  "id": "GHSA-p2qj-r53j-h3xj",
  "modified": "2024-09-19T18:42:58.200753Z",
  "published": "2024-09-19T06:31:36Z",
  "aliases": [
    "CVE-2024-46946"
  ],
  "summary": "LangChain Experimental Eval Injection vulnerability",
  "details": "langchain_experimental (aka LangChain Experimental) 0.1.17 through 0.3.0 for LangChain allows attackers to execute arbitrary code through sympy.sympify (which uses eval) in LLMSymbolicMathChain. LLMSymbolicMathChain was introduced in fcccde406dd9e9b05fc9babcbeb9ff527b0ec0c6 (2023-10-05).",
  "affected": [
    {
      "package": {
        "ecosystem": "PyPI",
        "name": "langchain-experimental",
        "purl": "pkg:pypi/langchain-experimental"
      },
      "ranges": [
        {
          "type": "ECOSYSTEM",
          "events": [
            {
              "introduced": "0.1.17"
            },
            {
              "last_affected": "0.3.0"
            }
          ]
        }
      ],
      "versions": [
        "0.3.0",
        "0.3.0.dev1"
      ],
      "database_specific": {
        "source": "https://github.com/github/advisory-database/blob/main/advisories/github-reviewed/2024/09/GHSA-p2qj-r53j-h3xj/GHSA-p2qj-r53j-h3xj.json"
      }
    }
  ],
  "references": [
    {
      "type": "ADVISORY",
      "url": "https://nvd.nist.gov/vuln/detail/CVE-2024-46946"
    },
    {
      "type": "WEB",
      "url": "https://docs.sympy.org/latest/modules/codegen.html"
    },
    {
      "type": "WEB",
      "url": "https://gist.github.com/12end/68c0c58d2564ef4141bccd4651480820#file-cve-2024-46946-txt"
    },
    {
      "type": "PACKAGE",
      "url": "https://github.com/langchain-ai/langchain"
    },
    {
      "type": "WEB",
      "url": "https://github.com/langchain-ai/langchain/releases/tag/langchain-experimental%3D%3D0.3.0"
    }
  ]
}