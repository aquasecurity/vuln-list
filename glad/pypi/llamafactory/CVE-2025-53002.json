{
  "Identifier": "CVE-2025-53002",
  "PackageSlug": "pypi/llamafactory",
  "Title": "LLaMA-Factory allows Code Injection through improper vhead_file safeguards",
  "Description": "A critical remote code execution vulnerability was discovered during the Llama Factory training process. This vulnerability arises because the `vhead_file` is loaded without proper safeguards, allowing malicious attackers to execute arbitrary malicious code on the host system simply by passing a malicious `Checkpoint path` parameter through the `WebUI` interface. The attack is stealthy, as the victim remains unaware of the exploitation. The root cause is that the `vhead_file` argument is loaded without the secure parameter `weights_only=True`.\n\nNote: In torch versions \u003c2.6, the default setting is `weights_only=False`, and Llama Factory's `setup.py` only requires `torch\u003e=2.0.0`.",
  "Date": "2025-06-27",
  "Pubdate": "2025-06-27",
  "AffectedRange": "\u003c=0.9.3",
  "FixedVersions": [],
  "AffectedVersions": "All versions up to 0.9.3",
  "NotImpacted": "",
  "Solution": "Unfortunately, there is no solution available yet.",
  "Urls": [
    "https://nvd.nist.gov/vuln/detail/CVE-2025-53002",
    "https://github.com/advisories/GHSA-xj56-p8mm-qmxj",
    "https://github.com/hiyouga/LLaMA-Factory/security/advisories/GHSA-xj56-p8mm-qmxj",
    "https://github.com/hiyouga/LLaMA-Factory/commit/bb7bf51554d4ba8432333c35a5e3b52705955ede",
    "https://github.com/hiyouga/LLaMA-Factory"
  ],
  "CvssV2": "",
  "CvssV3": "CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:L/A:H",
  "UUID": "c7895cb2-8362-409c-8c1c-b9c1a2e51492"
}