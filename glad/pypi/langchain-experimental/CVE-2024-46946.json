{
  "Identifier": "CVE-2024-46946",
  "PackageSlug": "pypi/langchain-experimental",
  "Title": "LangChain Experimental Eval Injection vulnerability",
  "Description": "langchain_experimental (aka LangChain Experimental) 0.1.17 through 0.3.0 for LangChain allows attackers to execute arbitrary code through sympy.sympify (which uses eval) in LLMSymbolicMathChain. LLMSymbolicMathChain was introduced in fcccde406dd9e9b05fc9babcbeb9ff527b0ec0c6 (2023-10-05).",
  "Date": "2024-09-19",
  "Pubdate": "2024-09-19",
  "AffectedRange": "\u003e=0.1.17,\u003c=0.3.0",
  "FixedVersions": [],
  "AffectedVersions": "All versions starting from 0.1.17 up to 0.3.0",
  "NotImpacted": "",
  "Solution": "Unfortunately, there is no solution available yet.",
  "Urls": [
    "https://nvd.nist.gov/vuln/detail/CVE-2024-46946",
    "https://github.com/advisories/GHSA-p2qj-r53j-h3xj",
    "https://docs.sympy.org/latest/modules/codegen.html",
    "https://gist.github.com/12end/68c0c58d2564ef4141bccd4651480820#file-cve-2024-46946-txt",
    "https://github.com/langchain-ai/langchain",
    "https://github.com/langchain-ai/langchain/releases/tag/langchain-experimental%3D%3D0.3.0"
  ],
  "CvssV2": "",
  "CvssV3": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H",
  "UUID": "c53ff849-00f9-4115-9115-4439a9f8fb10"
}