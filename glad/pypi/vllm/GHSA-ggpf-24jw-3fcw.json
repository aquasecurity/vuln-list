{
  "Identifier": "GHSA-ggpf-24jw-3fcw",
  "PackageSlug": "pypi/vllm",
  "Title": "CVE-2025-24357 Malicious model remote code execution fix bypass with PyTorch \u003c 2.6.0",
  "Description": "https://github.com/vllm-project/vllm/security/advisories/GHSA-rh4j-5rhw-hr54 reported a vulnerability where loading a malicious model could result in code execution on the vllm host. The fix applied to specify `weights_only=True` to calls to `torch.load()` did not solve the problem prior to PyTorch 2.6.0.\n\nPyTorch has issued a new CVE about this problem: https://github.com/advisories/GHSA-53q9-r3pm-6pq6\n\nThis means that versions of vLLM using PyTorch before 2.6.0 are vulnerable to this problem.",
  "Date": "2025-04-23",
  "Pubdate": "2025-04-23",
  "AffectedRange": "\u003c0.8.0",
  "FixedVersions": [
    "0.8.0"
  ],
  "AffectedVersions": "All versions before 0.8.0",
  "NotImpacted": "All versions starting from 0.8.0",
  "Solution": "Upgrade to version 0.8.0 or above.",
  "Urls": [
    "https://github.com/advisories/GHSA-ggpf-24jw-3fcw",
    "https://github.com/pytorch/pytorch/security/advisories/GHSA-53q9-r3pm-6pq6",
    "https://github.com/vllm-project/vllm/security/advisories/GHSA-ggpf-24jw-3fcw",
    "https://github.com/vllm-project/vllm/security/advisories/GHSA-rh4j-5rhw-hr54",
    "https://github.com/vllm-project/vllm"
  ],
  "CvssV2": "",
  "CvssV3": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H",
  "UUID": "66af4606-189c-45ae-a1ee-360bcfb6cdf5"
}