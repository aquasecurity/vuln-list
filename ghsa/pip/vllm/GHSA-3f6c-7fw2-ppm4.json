{
  "Severity": "HIGH",
  "UpdatedAt": "2025-10-07T22:14:15Z",
  "Package": {
    "Ecosystem": "PIP",
    "Name": "vllm"
  },
  "Advisory": {
    "DatabaseId": 315774,
    "Id": "GSA_kwCzR0hTQS0zZjZjLTdmdzItcHBtNM4ABNF-",
    "GhsaId": "GHSA-3f6c-7fw2-ppm4",
    "References": [
      {
        "Url": "https://github.com/vllm-project/vllm/security/advisories/GHSA-3f6c-7fw2-ppm4"
      },
      {
        "Url": "https://nvd.nist.gov/vuln/detail/CVE-2025-6242"
      },
      {
        "Url": "https://github.com/vllm-project/vllm/commit/9d9a2b77f19f68262d5e469c4e82c0f6365ad72d"
      },
      {
        "Url": "https://access.redhat.com/security/cve/CVE-2025-6242"
      },
      {
        "Url": "https://bugzilla.redhat.com/show_bug.cgi?id=2373716"
      },
      {
        "Url": "https://github.com/advisories/GHSA-3f6c-7fw2-ppm4"
      }
    ],
    "Identifiers": [
      {
        "Type": "GHSA",
        "Value": "GHSA-3f6c-7fw2-ppm4"
      },
      {
        "Type": "CVE",
        "Value": "CVE-2025-6242"
      }
    ],
    "Description": "### Summary\n\nA Server-Side Request Forgery (SSRF) vulnerability exists in the `MediaConnector` class within the vLLM project's multimodal feature set. The `load_from_url` and `load_from_url_async` methods fetch and process media from user-provided URLs without adequate restrictions on the target hosts. This allows an attacker to coerce the vLLM server into making arbitrary requests to internal network resources.\n\nThis vulnerability is particularly critical in containerized environments like `llm-d`, where a compromised vLLM pod could be used to scan the internal network, interact with other pods, and potentially cause denial of service or access sensitive data. For example, an attacker could make the vLLM pod send malicious requests to an internal `llm-d` management endpoint, leading to system instability by falsely reporting metrics like the KV cache state.\n\n### Vulnerability Details\n\nThe core of the vulnerability lies in the `MediaConnector.load_from_url` method and its asynchronous counterpart. These methods accept a URL string to fetch media content (images, audio, video).\n\nhttps://github.com/vllm-project/vllm/blob/119f683949dfed10df769fe63b2676d7f1eb644e/vllm/multimodal/utils.py#L97-L113\n\nThe function directly processes URLs with `http`, `https`, and `file` schemes. An attacker can supply a URL pointing to an internal IP address or a `localhost` endpoint. The vLLM server will then initiate a connection to this internal resource.\n\n* **HTTP/HTTPS Scheme:** An attacker can craft a request like `{\"image_url\": \"http://127.0.0.1:8080/internal_api\"}`. The vLLM server will send a GET request to this internal endpoint.\n* **File Scheme:** The `_load_file_url` method attempts to restrict file access to a subdirectory defined by `--allowed-local-media-path`. While this is a good security measure for local file access, it does not prevent network-based SSRF attacks.\n\n### Impact in `llm-d` Environments\n\nThe risk is significantly amplified in orchestrated environments such as `llm-d`, where multiple pods communicate over an internal network.\n\n1.  **Denial of Service (DoS):** An attacker could target internal management endpoints of other services within the `llm-d` cluster. For instance, if a monitoring or metrics service is exposed internally, an attacker could send malformed requests to it. A specific example is an attacker causing the vLLM pod to call an internal API that reports a false KV cache utilization, potentially triggering incorrect scaling decisions or even a system shutdown.\n\n2.  **Internal Network Reconnaissance:** Attackers can use the vulnerability to scan the internal network for open ports and services by providing URLs like `http://10.0.0.X:PORT` and observing the server's response time or error messages.\n\n3.  **Interaction with Internal Services:** Any unsecured internal service becomes a potential target. This could include databases, internal APIs, or other model pods that might not have robust authentication, as they are not expected to be directly exposed.\n\nDelegating this security responsibility to an upper-level orchestrator like `llm-d` is problematic. **The orchestrator cannot easily distinguish between legitimate requests initiated by the vLLM engine for its own purposes and malicious requests originating from user input, thus complicating traffic filtering rules and increasing management overhead.**\n\n### Fix\n\nSee the `--allowed-media-domains` option discussed here: https://docs.vllm.ai/en/latest/usage/security.html#4-restrict-domains-access-for-media-urls",
    "Origin": "UNSPECIFIED",
    "PublishedAt": "2025-10-07T22:14:15Z",
    "Severity": "HIGH",
    "Summary": "vLLM is vulnerable to Server-Side Request Forgery (SSRF) through `MediaConnector` class",
    "UpdatedAt": "2025-10-27T20:00:22Z",
    "WithdrawnAt": "",
    "CVSS": {
      "Score": 7.1,
      "VectorString": "CVSS:3.1/AV:N/AC:H/PR:L/UI:N/S:U/C:H/I:L/A:H"
    }
  },
  "Versions": [
    {
      "FirstPatchedVersion": {
        "Identifier": "0.11.0"
      },
      "VulnerableVersionRange": "\u003e= 0.5.0, \u003c 0.11.0"
    }
  ]
}