{
  "Severity": "MODERATE",
  "UpdatedAt": "2024-09-17T21:56:56Z",
  "Package": {
    "Ecosystem": "PIP",
    "Name": "vllm"
  },
  "Advisory": {
    "DatabaseId": 260528,
    "Id": "GSA_kwCzR0hTQS13YzM2LTk2OTQtZjlyZs4AA_mw",
    "GhsaId": "GHSA-wc36-9694-f9rf",
    "References": [
      {
        "Url": "https://nvd.nist.gov/vuln/detail/CVE-2024-8939"
      },
      {
        "Url": "https://access.redhat.com/security/cve/CVE-2024-8939"
      },
      {
        "Url": "https://bugzilla.redhat.com/show_bug.cgi?id=2312782"
      },
      {
        "Url": "https://github.com/vllm-project/vllm/issues/6137"
      },
      {
        "Url": "https://github.com/advisories/GHSA-wc36-9694-f9rf"
      }
    ],
    "Identifiers": [
      {
        "Type": "GHSA",
        "Value": "GHSA-wc36-9694-f9rf"
      },
      {
        "Type": "CVE",
        "Value": "CVE-2024-8939"
      }
    ],
    "Description": "A vulnerability was found in the ilab model serve component, where improper handling of the best_of parameter in the vllm JSON web API can lead to a Denial of Service (DoS). The API used for LLM-based sentence or chat completion accepts a best_of parameter to return the best completion from several options. When this parameter is set to a large value, the API does not handle timeouts or resource exhaustion properly, allowing an attacker to cause a DoS by consuming excessive system resources. This leads to the API becoming unresponsive, preventing legitimate users from accessing the service.",
    "Origin": "UNSPECIFIED",
    "PublishedAt": "2024-09-17T18:33:26Z",
    "Severity": "MODERATE",
    "Summary": "vLLM Denial of Service via the best_of parameter",
    "UpdatedAt": "2024-09-17T21:56:56Z",
    "WithdrawnAt": "",
    "CVSS": {
      "Score": 6.2,
      "VectorString": "CVSS:3.1/AV:L/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H"
    }
  },
  "Versions": [
    {
      "FirstPatchedVersion": {
        "Identifier": ""
      },
      "VulnerableVersionRange": "\u003c= 0.5.0.post1"
    }
  ]
}